{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rules of survival\n",
    "\n",
    "### Mini-project\n",
    "\n",
    "In this small project you will use the PRISM Rule Learner algorithm to learn some rules about COVID-19 comorbidity factors. Write as much about your findings as possible. You may add external information/additional datasets for an extra-credit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Algorithm\n",
    "\n",
    "Copy your implementation of the correct and tested algorithm in the cell below. You do not need to supply any comments or explanations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class Rule:\n",
    "    def __init__(self, class_label):\n",
    "        self.conditions = []  # list of conditions\n",
    "        self.class_label = class_label  # rule class\n",
    "        self.accuracy = 0\n",
    "        self.coverage = 0\n",
    "\n",
    "    def addCondition(self, condition):\n",
    "        self.conditions.append(condition)\n",
    "\n",
    "    def setParams(self, accuracy, coverage):\n",
    "        self.accuracy = accuracy\n",
    "        self.coverage = coverage\n",
    "    \n",
    "    # Human-readable printing of this Rule\n",
    "    def __repr__(self):\n",
    "        return \"If {} then {}. Coverage:{}, accuracy: {}\".format(self.conditions, self.class_label,\n",
    "                                                                 self.coverage, self.accuracy)\n",
    "\n",
    "class Condition:\n",
    "    def __init__(self, attribute, value, true_false = None):\n",
    "        self.attribute = attribute\n",
    "        self.value = value\n",
    "        self.true_false = true_false\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.true_false is None:\n",
    "            return \"{}={}\".format(self.attribute, self.value)\n",
    "        else:\n",
    "            return \"{}>={}:{}\".format(self.attribute, self.value, self.true_false)\n",
    "        \n",
    "def refine_rule(columns, covered_subset, class_label, min_coverage=30, min_accuracy=0.6, current_rule = None, colTypes = None):\n",
    "    \n",
    "    if (current_rule == None):\n",
    "        current_rule = Rule(class_label)\n",
    "        \n",
    "\n",
    "    bestAcc = 0\n",
    "    bestCov = 0\n",
    "    bestCondition = None\n",
    "    curAcc = 0\n",
    "    curCov = 0 \n",
    "\n",
    "    # We start by testing all possible columns/traits until we find the best one:\n",
    "    for trait in columns:\n",
    "        if trait == columns[-1]:\n",
    "            continue\n",
    "    \n",
    "        # If the trait is numeric\n",
    "        if colTypes[trait].loc['type'] == \"numeric\":\n",
    "            # We'll split by less than and ge. \n",
    "            \n",
    "            # Less than:\n",
    "            \n",
    "            for level in covered_subset[trait].unique().tolist():\n",
    "                ruleSubset = covered_subset[covered_subset[trait] < level] # Split by less than\n",
    "                if (len(ruleSubset) > 0):\n",
    "                    curAcc = len(ruleSubset[ruleSubset[columns[-1]] == class_label]) / len(ruleSubset)\n",
    "                    curCov = len(ruleSubset[ruleSubset[columns[-1]] == class_label])\n",
    "                    # Evaluate goodness of the rule\n",
    "                    if (curCov >= min_coverage):\n",
    "                        if (curAcc > bestAcc):\n",
    "                            bestAcc = curAcc\n",
    "                            bestCov = curCov\n",
    "                            bestCondition = Condition(trait, level, False)\n",
    "                        if (curAcc == bestAcc):\n",
    "                            if (curCov > bestCov):\n",
    "                                bestCov = curCov\n",
    "                                bestCondition = Condition(trait, level, False)\n",
    "                \n",
    "                # Now check the >= case:\n",
    "\n",
    "                ruleSubset = covered_subset[covered_subset[trait] >= level] # Split by ge\n",
    "                if (len(ruleSubset) > 0):\n",
    "                    curAcc = len(ruleSubset[ruleSubset[columns[-1]] == class_label]) / len(ruleSubset)\n",
    "                    curCov = len(ruleSubset[ruleSubset[columns[-1]] == class_label])\n",
    "                    # Evaluate goodness of the rule\n",
    "                    if (curCov >= min_coverage):\n",
    "                        if (curAcc > bestAcc):\n",
    "                            bestAcc = curAcc\n",
    "                            bestCov = curCov\n",
    "                            bestCondition = Condition(trait, level, True)\n",
    "                        if (curAcc == bestAcc):\n",
    "                            if (curCov > bestCov):\n",
    "                                bestCov = curCov\n",
    "                                bestCondition = Condition(trait, level, True)\n",
    "                            \n",
    "            continue # Go to the next loop\n",
    "        \n",
    "         \n",
    "        # If our trait is categorical:\n",
    "        for typeTrait in covered_subset[trait].unique().tolist():\n",
    "            ruleSubset = covered_subset[covered_subset[trait] == typeTrait]\n",
    "            # Now test for accuracy of the rule:\n",
    "            # We can use .size which normally \n",
    "            # returns total number of element in the dataframe\n",
    "            # but since we would divide both numbers by the number of columns\n",
    "            # to get accuracy, we can just do this\n",
    "\n",
    "            \n",
    "            curAcc = len(ruleSubset[ruleSubset[columns[-1]] == class_label]) / len(ruleSubset)\n",
    "            curCov = len(ruleSubset[ruleSubset[columns[-1]] == class_label])\n",
    "            if (curCov >= min_coverage):\n",
    "                if (curAcc > bestAcc):\n",
    "                    bestAcc = curAcc\n",
    "                    bestCov = curCov\n",
    "                    bestCondition = Condition(trait, typeTrait)\n",
    "\n",
    "                # If we have another rule with the same accuracy, \n",
    "                # choose the one with the better coverage\n",
    "                if (curAcc == bestAcc):\n",
    "                    if curCov > bestCov:\n",
    "                        bestCov = curCov\n",
    "                        bestCondition = Condition(trait, typeTrait)\n",
    "\n",
    "    # If refining does not improve our accuracy, we break\n",
    "    # I'm actually pretty sure this never \n",
    "    if (bestAcc == current_rule.accuracy):\n",
    "        return(None, None)\n",
    "    \n",
    "    # If we have no rule, break\n",
    "    if (bestCondition == None):\n",
    "        return(None, None)\n",
    "    # Otherwise, add the rule to the list and\n",
    "    # shorten the subset\n",
    "    current_rule.addCondition(bestCondition)\n",
    "    current_rule.setParams(bestAcc, bestCov)\n",
    "    covered_subset = covered_subset[covered_subset[bestCondition.attribute] == bestCondition.value]\n",
    "    return (current_rule, covered_subset)\n",
    "                            \n",
    "    \n",
    "    \n",
    "\n",
    "# Ok, now we can learn_one_rule!\n",
    "\n",
    "def learn_one_rule(columns, data, class_label, min_coverage=30, min_accuracy=0.6, colType = None):\n",
    "    # Make a copy of columns so we can delete from it. \n",
    "    # Otherwise we'd be destorying columns\n",
    "    columnsCopy = columns.copy().tolist()\n",
    "    \n",
    "    # Refine once from None, this will create the best first rule we want\n",
    "    current_rule, covered_subset = refine_rule(columnsCopy, data.copy(), class_label, min_coverage, min_accuracy, None, colType)\n",
    "    \n",
    "    # If we got None out, it means there is no rule that meets min_coverage\n",
    "    if (current_rule == None):\n",
    "        return (None, None)\n",
    "    \n",
    "    # Remove the trait from the list of eligbile traits\n",
    "    columnsCopy.remove(current_rule.conditions[-1].attribute)\n",
    "    \n",
    "    # We will refine while our rule isn't perfect and there are \n",
    "    # traits left to add\n",
    "    while current_rule.accuracy < 1 and len(columnsCopy) > 1:\n",
    "        temp_rule, temp_subset = refine_rule(columnsCopy, covered_subset,\n",
    "                                             class_label, min_coverage, min_accuracy, current_rule, colType)\n",
    "        if (temp_rule != None):\n",
    "            current_rule = temp_rule\n",
    "            covered_subset = temp_subset\n",
    "            columnsCopy.remove(current_rule.conditions[-1].attribute)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "    if current_rule.accuracy < min_accuracy:\n",
    "        return (None, None)\n",
    "    \n",
    "    return (current_rule, covered_subset)\n",
    "\n",
    "def learn_rules (columns, data, classes=None, \n",
    "    min_coverage = 30, min_accuracy = 0.6):\n",
    "    # List of final rules\n",
    "    rules = []\n",
    "    \n",
    "    # If list of classes of interest is not provided - it is extracted from the last column of data\n",
    "    if classes is not None:\n",
    "        class_labels = classes\n",
    "    else:\n",
    "        class_labels = data[columns[-1]].unique().tolist()\n",
    "\n",
    "    current_data = data.copy()\n",
    "    \n",
    "    # We can pre-process to determine if something is a numeric trait. \n",
    "    # We'll use two rules here:\n",
    "    # 1. If the Trait is all numeric\n",
    "    # 2. If there are a certain number of unique oberservations\n",
    "    #    in the dataset, say more than 10. \n",
    "    \n",
    "\n",
    "    types = []\n",
    "    cols = data.columns\n",
    "    for column in cols:\n",
    "        print(column)\n",
    "        if data[column].dtype == 'int64':\n",
    "            if len(data[column].unique()) >= 10:\n",
    "                types.append(\"numeric\")\n",
    "            else:\n",
    "                types.append(\"categorical\")\n",
    "        else:\n",
    "            types.append(\"categorical\")\n",
    "\n",
    "    colTypes = pd.DataFrame(columns = cols)\n",
    "\n",
    "    colTypes.loc['type'] = types\n",
    "    \n",
    "    \n",
    "    # This follows the logic of the original PRISM algorithm\n",
    "    # It processes each class in turn. \n",
    "    for class_label in class_labels:\n",
    "        done = False\n",
    "        while len(current_data) > min_coverage and not done:\n",
    "            # Learn one rule \n",
    "            rule, subset = learn_one_rule(columns, current_data, class_label, min_coverage, min_accuracy, colTypes)\n",
    "            \n",
    "            # If the best rule does not pass the coverage threshold - we are done with this class\n",
    "            if rule is None:\n",
    "                break\n",
    "\n",
    "            # If we get the rule with accuracy and coverage above threshold\n",
    "            \n",
    "            if rule.accuracy >= min_accuracy:\n",
    "                rules.append(rule)\n",
    "\n",
    "                # We're going to say that `subset` is the rows that need to be removed. \n",
    "                # We can drop by matching up the indices\n",
    "                current_data = current_data.drop(index=subset.index)\n",
    "                   \n",
    "            else:\n",
    "                done = True         \n",
    "                \n",
    "    return rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Titanic dataset: the rules of survival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our very familiar Titanic [dataset](https://docs.google.com/spreadsheets/d/1QGNxqRU02eAvTGih1t0cErB5R05mdOdUBgJZACGcuvs/edit?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../datasets/titanic.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows 714\n",
      "Columns: ['Pclass' 'Sex' 'Age' 'Survived']\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "\n",
    "# take a subset of attributes\n",
    "data = data[['Pclass', 'Sex', 'Age', 'Survived']]\n",
    "\n",
    "# drop all columns and rows with missing values\n",
    "data = data.dropna(how=\"any\")\n",
    "print(\"Total rows\", len(data))\n",
    "\n",
    "column_list = data.columns.to_numpy()\n",
    "print(\"Columns:\", column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass\n",
      "Sex\n",
      "Age\n",
      "Survived\n",
      "If [Sex=female, Pclass=1] then 1. Coverage:82, accuracy: 0.9647058823529412\n",
      "If [Sex=female, Pclass=2] then 1. Coverage:68, accuracy: 0.918918918918919\n",
      "If [Pclass=2] then 0. Coverage:84, accuracy: 0.8484848484848485\n",
      "If [Sex=male, Pclass=3] then 0. Coverage:215, accuracy: 0.849802371541502\n"
     ]
    }
   ],
   "source": [
    "# we can set different accuracy thresholds\n",
    "# here we can reorder class labels - to first learn the rules with class label \"survived\".\n",
    "rules = learn_rules(column_list, data, [1,0], 30, 0.7)\n",
    "for rule in rules[:10]:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Coronavirus: symptoms and outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coronavirus [dataset](https://drive.google.com/file/d/1uVd09ekR1ArLrA8qN-Xtu4l-FFbmetVy/view?usp=sharing) (preprocessed as outlined [here](rules_motivation.ipynb))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../datasets/covid_categorical_good.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sex', 'age', 'diabetes', 'copd', 'asthma', 'imm_supr', 'hypertension',\n",
       "       'cardiovascular', 'obesity', 'renal_chronic', 'tobacco', 'outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "data = data.dropna(how=\"any\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most accurate rules will have class label \"alive\". There could be too many rules, and we might never get to the class label \"dead\" if we rank them by accuracy. \n",
    "\n",
    "If we want to see which combination of attributes leads to \"dead\", we might want to run the algorithm with only this class label and set the lower accuracy threshold.\n",
    "\n",
    "Remove the _age_ attribute and run your algorithm with parameters shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If [renal_chronic=yes, diabetes=yes, cardiovascular=yes, obesity=no, sex=male, imm_supr=no, hypertension=yes, asthma=no, tobacco=no, copd=no] then dead. Coverage:36, accuracy: 0.6206896551724138\n",
      "If [renal_chronic=yes, diabetes=yes, obesity=no, copd=yes, asthma=no, hypertension=yes, imm_supr=no, tobacco=no] then dead. Coverage:32, accuracy: 0.6274509803921569\n"
     ]
    }
   ],
   "source": [
    "# We really want to learn first what makes covid deadly\n",
    "class_labels = [\"dead\"]\n",
    "data_categorical = data.drop(columns = ['age'])\n",
    "column_list = data_categorical.columns.tolist()\n",
    "rules = learn_rules(column_list, data_categorical, class_labels, 30, 0.6)\n",
    "\n",
    "for rule in rules[:20]:\n",
    "    print(rule)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try on both classes and for the entire dataset including _age_. Collect top 20 most accurate rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex\n",
      "age\n",
      "diabetes\n",
      "copd\n",
      "asthma\n",
      "imm_supr\n",
      "hypertension\n",
      "cardiovascular\n",
      "obesity\n",
      "renal_chronic\n",
      "tobacco\n",
      "outcome\n",
      "If [age>=26:False, hypertension=no, obesity=no, tobacco=yes, sex=female] then alive. Coverage:94, accuracy: 1.0\n",
      "If [age>=26:False, hypertension=no, obesity=no, renal_chronic=no, diabetes=no, sex=female, asthma=no] then alive. Coverage:1401, accuracy: 0.9929128277817151\n",
      "If [age>=26:False, sex=male, obesity=no, renal_chronic=no, hypertension=yes] then alive. Coverage:32, accuracy: 1.0\n",
      "If [age>=26:False, sex=male, obesity=no, renal_chronic=no, asthma=no, tobacco=no] then alive. Coverage:1375, accuracy: 0.9920634920634921\n",
      "If [age>=26:False, asthma=yes, obesity=yes] then alive. Coverage:30, accuracy: 1.0\n",
      "If [age>=26:False, asthma=yes, sex=male] then alive. Coverage:43, accuracy: 0.9772727272727273\n",
      "If [age>=26:False, tobacco=yes, obesity=no, sex=male] then alive. Coverage:169, accuracy: 0.9883040935672515\n",
      "If [age>=26:False, asthma=yes] then alive. Coverage:38, accuracy: 0.9743589743589743\n",
      "If [age>=26:False, obesity=yes, diabetes=no, sex=female] then alive. Coverage:196, accuracy: 0.9751243781094527\n",
      "If [age>=26:False, sex=male, renal_chronic=no, tobacco=no, hypertension=no] then alive. Coverage:171, accuracy: 0.9827586206896551\n",
      "If [age>=26:False, tobacco=yes, sex=male, imm_supr=no] then alive. Coverage:43, accuracy: 0.9555555555555556\n",
      "If [age>=26:False, renal_chronic=no, diabetes=no, copd=no, imm_supr=no] then alive. Coverage:32, accuracy: 0.9142857142857143\n"
     ]
    }
   ],
   "source": [
    "# This may take some time to run (took 12 min on my computer - what about your implementation?)\n",
    "age_column_list = data.columns\n",
    "rules = learn_rules (age_column_list, data, None, 30, 0.9)\n",
    "for rule in rules[:20]:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Discussion\n",
    "\n",
    "Write here a discussion about the rules that you have learned from both datasets. \n",
    "\n",
    "It took 7 and a half minutes to run on my computer!\n",
    "\n",
    "Did any of these rules surprise you?\n",
    "\n",
    "The Titantic rules weren't that surprising, it makes sense that women in the upper classes would survive at high rates, and that's what we see in the rules. \n",
    "\n",
    "For the COVID data, we see that the best pridicator of death involves rules like (asthma = no, tobacoo = no, and copd = no) then dead. While that rule had pretty low accuracy, we would expect the opposite conditions to make a person more likely to die. \n",
    "\n",
    "Do you have a meaningful logical explanation for these rules?\n",
    "\n",
    "For the Titantic ones, definitely. I remember learning when I was young that women and children were prioritized to get on the lifeboats, and then it makes sense that people physically higher on the decks would be more likely to live. \n",
    "\n",
    "Hmm, not sure if it's the most meaningful, but I have a potential explanation. Suppose that when COVID patients are taken into a hospital, the hospital screens for certain characteristics that would make a person more vulnerable. If a person had weaker lungs going into the hospital, it's possible they received better/more intensive treatment than patients who had stronger lungs. \n",
    "\n",
    "What additional research is needed to understand the meaning of your findings?\n",
    "\n",
    "It would probably have been good to have someone actually in the hospital recording how people were processed and triaged. It would also be nice if the data were a little cleaner, this dataset wasn't designed with COVID in mind, so its possible some people didn't survive and didn't have covid at all. \n",
    "\n",
    "An expert on the Titnatic's history and the way it was structued, laid out, and how the lifeboats were setup, would likely have a more in-depth explanation for the rules, but I think I got the gist of it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Repeating without the Refinement Stopper\n",
    "\n",
    "As I mentioned in the other document I wanted to repeat everything if I removed the refinement stopping condition that I placed on my algorithm and discuss those results as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_rule_rf(columns, covered_subset, class_label, min_coverage=30, min_accuracy=0.6, current_rule = None):\n",
    "    \n",
    "    if (current_rule == None):\n",
    "        current_rule = Rule(class_label)\n",
    "        \n",
    "\n",
    "    bestAcc = 0\n",
    "    bestCov = 0\n",
    "    bestCondition = None\n",
    "    curAcc = 0\n",
    "    curCov = 0 \n",
    "\n",
    "    # We start by testing all possible columns/traits until we find the best one:\n",
    "    for trait in columns:\n",
    "        if trait == columns[-1]:\n",
    "            continue\n",
    "        for typeTrait in covered_subset[trait].unique().tolist():\n",
    "            ruleSubset = covered_subset[covered_subset[trait] == typeTrait]\n",
    "            # Now test for accuracy of the rule:\n",
    "            # We can use .size which normally \n",
    "            # returns total number of element in the dataframe\n",
    "            # but since we would divide both numbers by the number of columns\n",
    "            # to get accuracy, we can just do this\n",
    "\n",
    "            curAcc = len(ruleSubset[ruleSubset[columns[-1]] == class_label]) / len(ruleSubset)\n",
    "            curCov = len(ruleSubset[ruleSubset[columns[-1]] == class_label])\n",
    "            if (curCov >= min_coverage):\n",
    "                if (curAcc > bestAcc):\n",
    "                    bestAcc = curAcc\n",
    "                    bestCov = curCov\n",
    "                    bestCondition = Condition(trait, typeTrait)\n",
    "\n",
    "                # If we have another rule with the same accuracy, \n",
    "                # choose the one with the better coverage\n",
    "                if (curAcc == bestAcc):\n",
    "                    if curCov > bestCov:\n",
    "                        bestCov = curCov\n",
    "                        bestCondition = Condition(trait, typeTrait)\n",
    "\n",
    "\n",
    "    # If we have no rule, break\n",
    "    if (bestCondition == None):\n",
    "        return(None, None)\n",
    "    # Otherwise, add the rule to the list and\n",
    "    # shorten the subset\n",
    "    current_rule.addCondition(bestCondition)\n",
    "    current_rule.setParams(bestAcc, bestCov)\n",
    "    covered_subset = covered_subset[covered_subset[bestCondition.attribute] == bestCondition.value]\n",
    "    return (current_rule, covered_subset)\n",
    "                            \n",
    "    \n",
    "    \n",
    "\n",
    "# Ok, now we can learn_one_rule!\n",
    "\n",
    "def learn_one_rule_rf(columns, data, class_label, min_coverage=30, min_accuracy=0.6):\n",
    "    # Make a copy of columns so we can delete from it. \n",
    "    # Otherwise we'd be destorying columns\n",
    "    columnsCopy = columns.copy()\n",
    "    \n",
    "    # Refine once, this will create the rule we want\n",
    "    current_rule, covered_subset = refine_rule_rf(columnsCopy, data.copy(), class_label, min_coverage, min_accuracy, None)\n",
    "    \n",
    "    # If we got None out, it means there is no rule that meets min_coverage\n",
    "    if (current_rule == None):\n",
    "        return (None, None)\n",
    "    \n",
    "    # Remove the trait from the list of eligbile traits\n",
    "    columnsCopy.remove(current_rule.conditions[-1].attribute)\n",
    "    \n",
    "    # We will refine while our rule isn't perfect and there are \n",
    "    # traits left to add\n",
    "    while current_rule.accuracy < 1 and len(columnsCopy) > 1:\n",
    "        temp_rule, temp_subset = refine_rule_rf(columnsCopy, covered_subset,\n",
    "                                             class_label, min_coverage, min_accuracy, current_rule)\n",
    "        if (temp_rule != None):\n",
    "            current_rule = temp_rule\n",
    "            covered_subset = temp_subset\n",
    "            columnsCopy.remove(current_rule.conditions[-1].attribute)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "    if current_rule.accuracy < min_accuracy:\n",
    "        return (None, None)\n",
    "    \n",
    "    return (current_rule, covered_subset)\n",
    "\n",
    "def learn_rules_rf (columns, data, classes=None, \n",
    "                 min_coverage = 30, min_accuracy = 0.6):\n",
    "    # List of final rules\n",
    "    rules = []\n",
    "    \n",
    "    # If list of classes of interest is not provided - it is extracted from the last column of data\n",
    "    if classes is not None:\n",
    "        class_labels = classes\n",
    "    else:\n",
    "        class_labels = data[columns[-1]].unique().tolist()\n",
    "\n",
    "    current_data = data.copy()\n",
    "    \n",
    "    # This follows the logic of the original PRISM algorithm\n",
    "    # It processes each class in turn. \n",
    "    for class_label in class_labels:\n",
    "        done = False\n",
    "        while len(current_data) > min_coverage and not done:\n",
    "            # Learn one rule \n",
    "            rule, subset = learn_one_rule_rf(columns, current_data, class_label, min_coverage, min_accuracy)\n",
    "            \n",
    "            # If the best rule does not pass the coverage threshold - we are done with this class\n",
    "            if rule is None:\n",
    "                break\n",
    "\n",
    "            # If we get the rule with accuracy and coverage above threshold\n",
    "            \n",
    "            if rule.accuracy >= min_accuracy:\n",
    "                rules.append(rule)\n",
    "\n",
    "                # We're going to say that `subset` is the rows that need to be removed. \n",
    "                # We can drop by matching up the indices\n",
    "                current_data = current_data.drop(index=subset.index)\n",
    "                   \n",
    "            else:\n",
    "                done = True         \n",
    "                \n",
    "    return rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Repeating Coronavirus and Titanic: Chaning Refining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our very familiar Titanic [dataset](https://docs.google.com/spreadsheets/d/1QGNxqRU02eAvTGih1t0cErB5R05mdOdUBgJZACGcuvs/edit?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../datasets/titanic.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows 714\n",
      "Columns: ['Pclass', 'Sex', 'Age', 'Survived']\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "\n",
    "# take a subset of attributes\n",
    "data = data[['Pclass', 'Sex', 'Age', 'Survived']]\n",
    "\n",
    "# drop all columns and rows with missing values\n",
    "data = data.dropna(how=\"any\")\n",
    "print(\"Total rows\", len(data))\n",
    "\n",
    "column_list = data.columns.to_numpy().tolist()\n",
    "print(\"Columns:\", column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If [Sex=female, Pclass=1] then 1. Coverage:82, accuracy: 0.9647058823529412\n",
      "If [Sex=female, Pclass=2] then 1. Coverage:68, accuracy: 0.918918918918919\n",
      "If [Pclass=2, Sex=male] then 0. Coverage:84, accuracy: 0.8484848484848485\n",
      "If [Sex=male, Pclass=3] then 0. Coverage:215, accuracy: 0.849802371541502\n"
     ]
    }
   ],
   "source": [
    "# we can set different accuracy thresholds\n",
    "# here we can reorder class labels - to first learn the rules with class label \"survived\".\n",
    "rules = learn_rules_rf(column_list, data, [1,0], 30, 0.7)\n",
    "for rule in rules[:10]:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coronavirus [dataset](https://drive.google.com/file/d/1uVd09ekR1ArLrA8qN-Xtu4l-FFbmetVy/view?usp=sharing) (preprocessed as outlined [here](rules_motivation.ipynb))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../datasets/covid_categorical_good.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sex', 'age', 'diabetes', 'copd', 'asthma', 'imm_supr', 'hypertension',\n",
       "       'cardiovascular', 'obesity', 'renal_chronic', 'tobacco', 'outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "data = data.dropna(how=\"any\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most accurate rules will have class label \"alive\". There could be too many rules, and we might never get to the class label \"dead\" if we rank them by accuracy. \n",
    "\n",
    "If we want to see which combination of attributes leads to \"dead\", we might want to run the algorithm with only this class label and set the lower accuracy threshold.\n",
    "\n",
    "Remove the _age_ attribute and run your algorithm with parameters shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If [renal_chronic=yes, diabetes=yes, cardiovascular=yes, obesity=no, sex=male, imm_supr=no, hypertension=yes, asthma=no, tobacco=no, copd=no] then dead. Coverage:36, accuracy: 0.6206896551724138\n",
      "If [renal_chronic=yes, diabetes=yes, obesity=no, copd=yes, asthma=no, hypertension=yes, imm_supr=no, tobacco=no] then dead. Coverage:32, accuracy: 0.6274509803921569\n"
     ]
    }
   ],
   "source": [
    "# We really want to learn first what makes covid deadly\n",
    "class_labels = [\"dead\"]\n",
    "data_categorical = data.drop(columns = ['age'])\n",
    "column_list = data_categorical.columns.tolist()\n",
    "rules = learn_rules_rf(column_list, data_categorical, class_labels, 30, 0.6)\n",
    "\n",
    "for rule in rules[:20]:\n",
    "    print(rule)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try on both classes and for the entire dataset including _age_. Collect top 20 most accurate rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If [age=6] then alive. Coverage:198, accuracy: 1.0\n",
      "If [age=14, sex=female] then alive. Coverage:189, accuracy: 1.0\n",
      "If [age=16, obesity=yes] then alive. Coverage:36, accuracy: 1.0\n",
      "If [age=16, sex=female, diabetes=no, copd=no, cardiovascular=no, obesity=no, hypertension=no, renal_chronic=no, tobacco=no, imm_supr=no, asthma=no] then alive. Coverage:225, accuracy: 0.995575221238938\n",
      "If [age=16, copd=no, obesity=no, diabetes=no, hypertension=no, renal_chronic=no, cardiovascular=no, tobacco=no, imm_supr=no, sex=male, asthma=no] then alive. Coverage:200, accuracy: 0.9950248756218906\n",
      "If [age=18, obesity=yes] then alive. Coverage:66, accuracy: 1.0\n",
      "If [age=7, imm_supr=no] then alive. Coverage:172, accuracy: 1.0\n",
      "If [age=18, imm_supr=no, sex=male] then alive. Coverage:255, accuracy: 1.0\n",
      "If [age=24, hypertension=yes] then alive. Coverage:76, accuracy: 1.0\n",
      "If [age=14, sex=male, copd=no, hypertension=no, tobacco=no, diabetes=no, renal_chronic=no, cardiovascular=no, imm_supr=no, obesity=no, asthma=no] then alive. Coverage:143, accuracy: 0.9930555555555556\n",
      "If [age=24, sex=female, tobacco=yes] then alive. Coverage:75, accuracy: 1.0\n",
      "If [age=24, sex=female, asthma=yes] then alive. Coverage:53, accuracy: 1.0\n",
      "If [age=24, sex=female, obesity=no, imm_supr=no, diabetes=no, copd=no, asthma=no, hypertension=no, tobacco=no, renal_chronic=no, cardiovascular=no] then alive. Coverage:1079, accuracy: 0.9990740740740741\n",
      "If [age=19, tobacco=yes] then alive. Coverage:57, accuracy: 1.0\n",
      "If [age=12, sex=female] then alive. Coverage:125, accuracy: 1.0\n",
      "If [age=19, asthma=yes] then alive. Coverage:36, accuracy: 1.0\n",
      "If [age=19, sex=male, imm_supr=no] then alive. Coverage:417, accuracy: 1.0\n",
      "If [age=20, asthma=yes] then alive. Coverage:41, accuracy: 1.0\n",
      "If [age=20, hypertension=no, sex=female, obesity=no, copd=no, asthma=no, imm_supr=no, cardiovascular=no, renal_chronic=no, diabetes=no, tobacco=no] then alive. Coverage:474, accuracy: 0.9978947368421053\n",
      "If [age=8, sex=female] then alive. Coverage:114, accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# This may take some time to run (took 12 min on my computer - what about your implementation?)\n",
    "age_column_list = data.columns.tolist()\n",
    "rules = learn_rules_rf (age_column_list, data, None, 30, 0.9)\n",
    "for rule in rules[:20]:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "The results here are similar to what we found before, but there are some slight differences. It looks like 5 of the top 20 rules are different, so the change to the algorithm made some slight changes here to the rules. The rules in the section are longer/more complicated than before too, so its possible that we're just reflecting the introduction of very complicated rules. \n",
    "\n",
    "For the dead rules, we found the exact same results--so the algorithm didn't change too much there. \n",
    "\n",
    "Finally, for the Titantic results, we got a different third rule, but the other two were the same. Again, the altered algorithm gave a more complicated rule, which is what we would expect with the modification I made. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2022 Marina Barsky. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
