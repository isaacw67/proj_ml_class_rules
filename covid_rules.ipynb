{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rules of survival\n",
    "\n",
    "### Mini-project\n",
    "\n",
    "In this small project you will use the PRISM Rule Learner algorithm to learn some rules about COVID-19 comorbidity factors. Write as much about your findings as possible. You may add external information/additional datasets for an extra-credit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Algorithm\n",
    "\n",
    "Copy your implementation of the correct and tested algorithm in the cell below. You do not need to supply any comments or explanations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class Rule:\n",
    "    def __init__(self, class_label):\n",
    "        self.conditions = []  # list of conditions\n",
    "        self.class_label = class_label  # rule class\n",
    "        self.accuracy = 0\n",
    "        self.coverage = 0\n",
    "\n",
    "    def addCondition(self, condition):\n",
    "        self.conditions.append(condition)\n",
    "\n",
    "    def setParams(self, accuracy, coverage):\n",
    "        self.accuracy = accuracy\n",
    "        self.coverage = coverage\n",
    "    \n",
    "    # Human-readable printing of this Rule\n",
    "    def __repr__(self):\n",
    "        return \"If {} then {}. Coverage:{}, accuracy: {}\".format(self.conditions, self.class_label,\n",
    "                                                                 self.coverage, self.accuracy)\n",
    "\n",
    "class Condition:\n",
    "    def __init__(self, attribute, value, true_false = None):\n",
    "        self.attribute = attribute\n",
    "        self.value = value\n",
    "        self.true_false = true_false\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.true_false is None:\n",
    "            return \"{}={}\".format(self.attribute, self.value)\n",
    "        else:\n",
    "            return \"{}>={}:{}\".format(self.attribute, self.value, self.true_false)\n",
    "        \n",
    "def refine_rule(columns, covered_subset, class_label, min_coverage=30, min_accuracy=0.6, current_rule = None):\n",
    "    \n",
    "    if (current_rule == None):\n",
    "        current_rule = Rule(class_label)\n",
    "        \n",
    "\n",
    "    bestAcc = 0\n",
    "    bestCov = 0\n",
    "    bestCondition = None\n",
    "    curAcc = 0\n",
    "    curCov = 0 \n",
    "\n",
    "    # We start by testing all possible columns/traits until we find the best one:\n",
    "    for trait in columns:\n",
    "        if trait == columns[-1]:\n",
    "            continue\n",
    "        for typeTrait in covered_subset[trait].unique().tolist():\n",
    "            ruleSubset = covered_subset[covered_subset[trait] == typeTrait]\n",
    "            # Now test for accuracy of the rule:\n",
    "            # We can use .size which normally \n",
    "            # returns total number of element in the dataframe\n",
    "            # but since we would divide both numbers by the number of columns\n",
    "            # to get accuracy, we can just do this\n",
    "\n",
    "            curAcc = len(ruleSubset[ruleSubset[columns[-1]] == class_label]) / len(ruleSubset)\n",
    "            curCov = len(ruleSubset[ruleSubset[columns[-1]] == class_label])\n",
    "            if (curCov >= min_coverage):\n",
    "                if (curAcc > bestAcc):\n",
    "                    bestAcc = curAcc\n",
    "                    bestCov = curCov\n",
    "                    bestCondition = Condition(trait, typeTrait)\n",
    "\n",
    "                # If we have another rule with the same accuracy, \n",
    "                # choose the one with the better coverage\n",
    "                if (curAcc == bestAcc):\n",
    "                    if curCov > bestCov:\n",
    "                        bestCov = curCov\n",
    "                        bestCondition = Condition(trait, typeTrait)\n",
    "\n",
    "    # If refining does not improve our accuracy, we break\n",
    "    if (bestAcc == current_rule.accuracy):\n",
    "        return(None, None)\n",
    "    \n",
    "    # If we have no rule, break\n",
    "    if (bestCondition == None):\n",
    "        return(None, None)\n",
    "    # Otherwise, add the rule to the list and\n",
    "    # shorten the subset\n",
    "    current_rule.addCondition(bestCondition)\n",
    "    current_rule.setParams(bestAcc, bestCov)\n",
    "    covered_subset = covered_subset[covered_subset[bestCondition.attribute] == bestCondition.value]\n",
    "    return (current_rule, covered_subset)\n",
    "                            \n",
    "    \n",
    "    \n",
    "\n",
    "# Ok, now we can learn_one_rule!\n",
    "\n",
    "def learn_one_rule(columns, data, class_label, min_coverage=30, min_accuracy=0.6):\n",
    "    # Make a copy of columns so we can delete from it. \n",
    "    # Otherwise we'd be destorying columns\n",
    "    columnsCopy = columns.copy()\n",
    "    \n",
    "    # Refine once, this will create the rule we want\n",
    "    current_rule, covered_subset = refine_rule(columnsCopy, data.copy(), class_label, min_coverage, min_accuracy, None)\n",
    "    \n",
    "    # If we got None out, it means there is no rule that meets min_coverage\n",
    "    if (current_rule == None):\n",
    "        return (None, None)\n",
    "    \n",
    "    # Remove the trait from the list of eligbile traits\n",
    "    columnsCopy.remove(current_rule.conditions[-1].attribute)\n",
    "    \n",
    "    # We will refine while our rule isn't perfect and there are \n",
    "    # traits left to add\n",
    "    while current_rule.accuracy < 1 and len(columnsCopy) > 1:\n",
    "        temp_rule, temp_subset = refine_rule(columnsCopy, covered_subset,\n",
    "                                             class_label, min_coverage, min_accuracy, current_rule)\n",
    "        if (temp_rule != None):\n",
    "            current_rule = temp_rule\n",
    "            covered_subset = temp_subset\n",
    "            columnsCopy.remove(current_rule.conditions[-1].attribute)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "    if current_rule.accuracy < min_accuracy:\n",
    "        return (None, None)\n",
    "    \n",
    "    return (current_rule, covered_subset)\n",
    "\n",
    "def learn_rules (columns, data, classes=None, \n",
    "                 min_coverage = 30, min_accuracy = 0.6):\n",
    "    # List of final rules\n",
    "    rules = []\n",
    "    \n",
    "    # If list of classes of interest is not provided - it is extracted from the last column of data\n",
    "    if classes is not None:\n",
    "        class_labels = classes\n",
    "    else:\n",
    "        class_labels = data[columns[-1]].unique().tolist()\n",
    "\n",
    "    current_data = data.copy()\n",
    "    \n",
    "    # This follows the logic of the original PRISM algorithm\n",
    "    # It processes each class in turn. \n",
    "    for class_label in class_labels:\n",
    "        done = False\n",
    "        while len(current_data) > min_coverage and not done:\n",
    "            # Learn one rule \n",
    "            rule, subset = learn_one_rule(columns, current_data, class_label, min_coverage, min_accuracy)\n",
    "            \n",
    "            # If the best rule does not pass the coverage threshold - we are done with this class\n",
    "            if rule is None:\n",
    "                break\n",
    "\n",
    "            # If we get the rule with accuracy and coverage above threshold\n",
    "            \n",
    "            if rule.accuracy >= min_accuracy:\n",
    "                rules.append(rule)\n",
    "\n",
    "                # We're going to say that `subset` is the rows that need to be removed. \n",
    "                # We can drop by matching up the indices\n",
    "                current_data = current_data.drop(index=subset.index)\n",
    "                   \n",
    "            else:\n",
    "                done = True         \n",
    "                \n",
    "    return rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Titanic dataset: the rules of survival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our very familiar Titanic [dataset](https://docs.google.com/spreadsheets/d/1QGNxqRU02eAvTGih1t0cErB5R05mdOdUBgJZACGcuvs/edit?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../datasets/titanic.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows 714\n",
      "Columns: ['Pclass', 'Sex', 'Age', 'Survived']\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "\n",
    "# take a subset of attributes\n",
    "data = data[['Pclass', 'Sex', 'Age', 'Survived']]\n",
    "\n",
    "# drop all columns and rows with missing values\n",
    "data = data.dropna(how=\"any\")\n",
    "print(\"Total rows\", len(data))\n",
    "\n",
    "column_list = data.columns.to_numpy().tolist()\n",
    "print(\"Columns:\", column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If [Sex=female, Pclass=1] then 1. Coverage:82, accuracy: 0.9647058823529412\n",
      "If [Sex=female, Pclass=2] then 1. Coverage:68, accuracy: 0.918918918918919\n",
      "If [Pclass=2] then 0. Coverage:84, accuracy: 0.8484848484848485\n",
      "If [Sex=male, Pclass=3] then 0. Coverage:215, accuracy: 0.849802371541502\n"
     ]
    }
   ],
   "source": [
    "# we can set different accuracy thresholds\n",
    "# here we can reorder class labels - to first learn the rules with class label \"survived\".\n",
    "rules = learn_rules(column_list, data, [1,0], 30, 0.7)\n",
    "for rule in rules[:10]:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Coronavirus: symptoms and outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coronavirus [dataset](https://drive.google.com/file/d/1uVd09ekR1ArLrA8qN-Xtu4l-FFbmetVy/view?usp=sharing) (preprocessed as outlined [here](rules_motivation.ipynb))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../datasets/covid_categorical_good.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sex', 'age', 'diabetes', 'copd', 'asthma', 'imm_supr', 'hypertension',\n",
       "       'cardiovascular', 'obesity', 'renal_chronic', 'tobacco', 'outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "data = data.dropna(how=\"any\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most accurate rules will have class label \"alive\". There could be too many rules, and we might never get to the class label \"dead\" if we rank them by accuracy. \n",
    "\n",
    "If we want to see which combination of attributes leads to \"dead\", we might want to run the algorithm with only this class label and set the lower accuracy threshold.\n",
    "\n",
    "Remove the _age_ attribute and run your algorithm with parameters shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If [renal_chronic=yes, diabetes=yes, cardiovascular=yes, obesity=no, sex=male, imm_supr=no, hypertension=yes, asthma=no, tobacco=no, copd=no] then dead. Coverage:36, accuracy: 0.6206896551724138\n",
      "If [renal_chronic=yes, diabetes=yes, obesity=no, copd=yes, asthma=no, hypertension=yes, imm_supr=no, tobacco=no] then dead. Coverage:32, accuracy: 0.6274509803921569\n"
     ]
    }
   ],
   "source": [
    "# We really want to learn first what makes covid deadly\n",
    "class_labels = [\"dead\"]\n",
    "data_categorical = data.drop(columns = ['age'])\n",
    "column_list = data_categorical.columns.tolist()\n",
    "rules = learn_rules(column_list, data_categorical, class_labels, 30, 0.6)\n",
    "\n",
    "for rule in rules[:20]:\n",
    "    print(rule)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try on both classes and for the entire dataset including _age_. Collect top 20 most accurate rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If [age=6] then alive. Coverage:198, accuracy: 1.0\n",
      "If [age=14, sex=female] then alive. Coverage:189, accuracy: 1.0\n",
      "If [age=16, obesity=yes] then alive. Coverage:36, accuracy: 1.0\n",
      "If [age=16, sex=female] then alive. Coverage:236, accuracy: 0.9957805907172996\n",
      "If [age=16] then alive. Coverage:218, accuracy: 0.9954337899543378\n",
      "If [age=18, obesity=yes] then alive. Coverage:66, accuracy: 1.0\n",
      "If [age=7, imm_supr=no] then alive. Coverage:172, accuracy: 1.0\n",
      "If [age=18, imm_supr=no, sex=male] then alive. Coverage:255, accuracy: 1.0\n",
      "If [age=24, hypertension=yes] then alive. Coverage:76, accuracy: 1.0\n",
      "If [age=14] then alive. Coverage:170, accuracy: 0.9941520467836257\n",
      "If [age=24, sex=female, tobacco=yes] then alive. Coverage:75, accuracy: 1.0\n",
      "If [age=24, sex=female, asthma=yes] then alive. Coverage:53, accuracy: 1.0\n",
      "If [age=24, sex=female, obesity=no, imm_supr=no, diabetes=no] then alive. Coverage:1086, accuracy: 0.9990800367985281\n",
      "If [age=19, tobacco=yes] then alive. Coverage:57, accuracy: 1.0\n",
      "If [age=12, sex=female] then alive. Coverage:125, accuracy: 1.0\n",
      "If [age=19, asthma=yes] then alive. Coverage:36, accuracy: 1.0\n",
      "If [age=19, sex=male, imm_supr=no] then alive. Coverage:417, accuracy: 1.0\n",
      "If [age=20, asthma=yes] then alive. Coverage:41, accuracy: 1.0\n",
      "If [age=20, hypertension=no, sex=female, obesity=no] then alive. Coverage:509, accuracy: 0.9980392156862745\n",
      "If [age=8, sex=female] then alive. Coverage:114, accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# This may take some time to run (took 12 min on my computer - what about your implementation?)\n",
    "age_column_list = data.columns.tolist()\n",
    "rules = learn_rules (age_column_list, data, None, 30, 0.9)\n",
    "for rule in rules[:20]:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Discussion\n",
    "\n",
    "Write here a discussion about the rules that you have learned from both datasets. \n",
    "\n",
    "It took 7 and a half minutes to run on my computer!\n",
    "\n",
    "Did any of these rules surprise you?\n",
    "\n",
    "The Titantic rules weren't that surprising, it makes sense that women in the upper classes would survive at high rates, and that's what we see in the rules. \n",
    "\n",
    "For the COVID data, we see that the best pridicator of death involves rules like (asthma = no, tobacoo = no, and copd = no) then dead. While that rule had pretty low accuracy, we would expect the opposite conditions to make a person more likely to die. \n",
    "\n",
    "Do you have a meaningful logical explanation for these rules?\n",
    "\n",
    "For the Titantic ones, definitely. I remember learning when I was young that women and children were prioritized to get on the lifeboats, and then it makes sense that people physically higher on the decks would be more likely to live. \n",
    "\n",
    "Hmm, not sure if it's the most meaningful, but I have a potential explanation. Suppose that when COVID patients are taken into a hospital, the hospital screens for certain characteristics that would make a person more vulnerable. If a person had weaker lungs going into the hospital, it's possible they received better/more intensive treatment than patients who had stronger lungs. \n",
    "\n",
    "What additional research is needed to understand the meaning of your findings?\n",
    "\n",
    "It would probably have been good to have someone actually in the hospital recording how people were processed and triaged. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Repeating without the Refinement Stopper\n",
    "\n",
    "As I mentioned in the other document I wanted to repeat everything if I removed the refinement stopping condition that I placed on my algorithm and discuss those results as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_rule_rf(columns, covered_subset, class_label, min_coverage=30, min_accuracy=0.6, current_rule = None):\n",
    "    \n",
    "    if (current_rule == None):\n",
    "        current_rule = Rule(class_label)\n",
    "        \n",
    "\n",
    "    bestAcc = 0\n",
    "    bestCov = 0\n",
    "    bestCondition = None\n",
    "    curAcc = 0\n",
    "    curCov = 0 \n",
    "\n",
    "    # We start by testing all possible columns/traits until we find the best one:\n",
    "    for trait in columns:\n",
    "        if trait == columns[-1]:\n",
    "            continue\n",
    "        for typeTrait in covered_subset[trait].unique().tolist():\n",
    "            ruleSubset = covered_subset[covered_subset[trait] == typeTrait]\n",
    "            # Now test for accuracy of the rule:\n",
    "            # We can use .size which normally \n",
    "            # returns total number of element in the dataframe\n",
    "            # but since we would divide both numbers by the number of columns\n",
    "            # to get accuracy, we can just do this\n",
    "\n",
    "            curAcc = len(ruleSubset[ruleSubset[columns[-1]] == class_label]) / len(ruleSubset)\n",
    "            curCov = len(ruleSubset[ruleSubset[columns[-1]] == class_label])\n",
    "            if (curCov >= min_coverage):\n",
    "                if (curAcc > bestAcc):\n",
    "                    bestAcc = curAcc\n",
    "                    bestCov = curCov\n",
    "                    bestCondition = Condition(trait, typeTrait)\n",
    "\n",
    "                # If we have another rule with the same accuracy, \n",
    "                # choose the one with the better coverage\n",
    "                if (curAcc == bestAcc):\n",
    "                    if curCov > bestCov:\n",
    "                        bestCov = curCov\n",
    "                        bestCondition = Condition(trait, typeTrait)\n",
    "\n",
    "\n",
    "    # If we have no rule, break\n",
    "    if (bestCondition == None):\n",
    "        return(None, None)\n",
    "    # Otherwise, add the rule to the list and\n",
    "    # shorten the subset\n",
    "    current_rule.addCondition(bestCondition)\n",
    "    current_rule.setParams(bestAcc, bestCov)\n",
    "    covered_subset = covered_subset[covered_subset[bestCondition.attribute] == bestCondition.value]\n",
    "    return (current_rule, covered_subset)\n",
    "                            \n",
    "    \n",
    "    \n",
    "\n",
    "# Ok, now we can learn_one_rule!\n",
    "\n",
    "def learn_one_rule_rf(columns, data, class_label, min_coverage=30, min_accuracy=0.6):\n",
    "    # Make a copy of columns so we can delete from it. \n",
    "    # Otherwise we'd be destorying columns\n",
    "    columnsCopy = columns.copy()\n",
    "    \n",
    "    # Refine once, this will create the rule we want\n",
    "    current_rule, covered_subset = refine_rule_rf(columnsCopy, data.copy(), class_label, min_coverage, min_accuracy, None)\n",
    "    \n",
    "    # If we got None out, it means there is no rule that meets min_coverage\n",
    "    if (current_rule == None):\n",
    "        return (None, None)\n",
    "    \n",
    "    # Remove the trait from the list of eligbile traits\n",
    "    columnsCopy.remove(current_rule.conditions[-1].attribute)\n",
    "    \n",
    "    # We will refine while our rule isn't perfect and there are \n",
    "    # traits left to add\n",
    "    while current_rule.accuracy < 1 and len(columnsCopy) > 1:\n",
    "        temp_rule, temp_subset = refine_rule_rf(columnsCopy, covered_subset,\n",
    "                                             class_label, min_coverage, min_accuracy, current_rule)\n",
    "        if (temp_rule != None):\n",
    "            current_rule = temp_rule\n",
    "            covered_subset = temp_subset\n",
    "            columnsCopy.remove(current_rule.conditions[-1].attribute)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "    if current_rule.accuracy < min_accuracy:\n",
    "        return (None, None)\n",
    "    \n",
    "    return (current_rule, covered_subset)\n",
    "\n",
    "def learn_rules_rf (columns, data, classes=None, \n",
    "                 min_coverage = 30, min_accuracy = 0.6):\n",
    "    # List of final rules\n",
    "    rules = []\n",
    "    \n",
    "    # If list of classes of interest is not provided - it is extracted from the last column of data\n",
    "    if classes is not None:\n",
    "        class_labels = classes\n",
    "    else:\n",
    "        class_labels = data[columns[-1]].unique().tolist()\n",
    "\n",
    "    current_data = data.copy()\n",
    "    \n",
    "    # This follows the logic of the original PRISM algorithm\n",
    "    # It processes each class in turn. \n",
    "    for class_label in class_labels:\n",
    "        done = False\n",
    "        while len(current_data) > min_coverage and not done:\n",
    "            # Learn one rule \n",
    "            rule, subset = learn_one_rule_rf(columns, current_data, class_label, min_coverage, min_accuracy)\n",
    "            \n",
    "            # If the best rule does not pass the coverage threshold - we are done with this class\n",
    "            if rule is None:\n",
    "                break\n",
    "\n",
    "            # If we get the rule with accuracy and coverage above threshold\n",
    "            \n",
    "            if rule.accuracy >= min_accuracy:\n",
    "                rules.append(rule)\n",
    "\n",
    "                # We're going to say that `subset` is the rows that need to be removed. \n",
    "                # We can drop by matching up the indices\n",
    "                current_data = current_data.drop(index=subset.index)\n",
    "                   \n",
    "            else:\n",
    "                done = True         \n",
    "                \n",
    "    return rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Repeating Coronavirus: symptoms and outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coronavirus [dataset](https://drive.google.com/file/d/1uVd09ekR1ArLrA8qN-Xtu4l-FFbmetVy/view?usp=sharing) (preprocessed as outlined [here](rules_motivation.ipynb))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../datasets/covid_categorical_good.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sex', 'age', 'diabetes', 'copd', 'asthma', 'imm_supr', 'hypertension',\n",
       "       'cardiovascular', 'obesity', 'renal_chronic', 'tobacco', 'outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "data = data.dropna(how=\"any\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most accurate rules will have class label \"alive\". There could be too many rules, and we might never get to the class label \"dead\" if we rank them by accuracy. \n",
    "\n",
    "If we want to see which combination of attributes leads to \"dead\", we might want to run the algorithm with only this class label and set the lower accuracy threshold.\n",
    "\n",
    "Remove the _age_ attribute and run your algorithm with parameters shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If [renal_chronic=yes, diabetes=yes, cardiovascular=yes, obesity=no, sex=male, imm_supr=no, hypertension=yes, asthma=no, tobacco=no, copd=no] then dead. Coverage:36, accuracy: 0.6206896551724138\n",
      "If [renal_chronic=yes, diabetes=yes, obesity=no, copd=yes, asthma=no, hypertension=yes, imm_supr=no, tobacco=no] then dead. Coverage:32, accuracy: 0.6274509803921569\n"
     ]
    }
   ],
   "source": [
    "# We really want to learn first what makes covid deadly\n",
    "class_labels = [\"dead\"]\n",
    "data_categorical = data.drop(columns = ['age'])\n",
    "column_list = data_categorical.columns.tolist()\n",
    "rules = learn_rules_rf(column_list, data_categorical, class_labels, 30, 0.6)\n",
    "\n",
    "for rule in rules[:20]:\n",
    "    print(rule)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try on both classes and for the entire dataset including _age_. Collect top 20 most accurate rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If [hypertension=no, sex=female, diabetes=no, tobacco=yes, obesity=no, asthma=yes, copd=no, imm_supr=no, renal_chronic=no, cardiovascular=no] then alive. Coverage:86, accuracy: 0.9885057471264368\n",
      "If [hypertension=no, sex=female, diabetes=no, tobacco=yes, obesity=no, copd=no, cardiovascular=yes] then alive. Coverage:36, accuracy: 1.0\n",
      "If [hypertension=no, sex=female, diabetes=no, tobacco=yes, obesity=no, copd=no, imm_supr=no, renal_chronic=no, asthma=no, cardiovascular=no] then alive. Coverage:2262, accuracy: 0.9762624082865775\n",
      "If [hypertension=no, sex=female, diabetes=no, asthma=yes, obesity=no, imm_supr=no, copd=no, cardiovascular=no, tobacco=no, renal_chronic=no] then alive. Coverage:1621, accuracy: 0.9671837708830548\n",
      "If [hypertension=no, sex=female, diabetes=no, obesity=no, copd=no, imm_supr=no, asthma=yes, tobacco=no] then alive. Coverage:31, accuracy: 0.96875\n",
      "If [hypertension=no, sex=female, diabetes=no, obesity=no, copd=no, imm_supr=no, renal_chronic=no, cardiovascular=no, asthma=no, tobacco=no] then alive. Coverage:52491, accuracy: 0.9620255484485823\n",
      "If [hypertension=no, asthma=yes, diabetes=no, copd=no, imm_supr=no, sex=female, tobacco=no, obesity=yes, renal_chronic=no, cardiovascular=no] then alive. Coverage:502, accuracy: 0.9561904761904761\n",
      "If [hypertension=no, asthma=yes, diabetes=no, obesity=no, copd=no, imm_supr=no, renal_chronic=no, tobacco=no, cardiovascular=no, sex=male] then alive. Coverage:1104, accuracy: 0.9509043927648578\n",
      "If [hypertension=no, diabetes=no, sex=female, tobacco=yes, obesity=yes, cardiovascular=no, asthma=yes, renal_chronic=no, copd=no, imm_supr=no] then alive. Coverage:40, accuracy: 0.975609756097561\n",
      "If [hypertension=no, diabetes=no, sex=female, obesity=yes, tobacco=yes, cardiovascular=no, copd=no, imm_supr=no, asthma=no, renal_chronic=no] then alive. Coverage:795, accuracy: 0.9453032104637337\n",
      "If [hypertension=no, diabetes=no, sex=female, obesity=yes, copd=no, cardiovascular=no, imm_supr=no, renal_chronic=no, asthma=no, tobacco=no] then alive. Coverage:9181, accuracy: 0.9365500357033562\n",
      "If [hypertension=no, diabetes=no, obesity=no, tobacco=yes, copd=no, asthma=yes, imm_supr=no, sex=male, renal_chronic=no, cardiovascular=no] then alive. Coverage:93, accuracy: 0.93\n",
      "If [hypertension=no, diabetes=no, obesity=no, tobacco=yes, copd=no, renal_chronic=no, imm_supr=no, cardiovascular=no, sex=male, asthma=no] then alive. Coverage:5454, accuracy: 0.9211281878061138\n",
      "If [hypertension=no, diabetes=no, obesity=no, copd=no, renal_chronic=no, imm_supr=no, cardiovascular=no, sex=male, asthma=no, tobacco=no] then alive. Coverage:57672, accuracy: 0.9117814456459875\n",
      "If [asthma=yes, hypertension=no, cardiovascular=yes, sex=male] then alive. Coverage:30, accuracy: 0.9090909090909091\n",
      "If [asthma=yes, hypertension=no, obesity=yes, sex=male, tobacco=yes, renal_chronic=no, copd=no, cardiovascular=no, imm_supr=no, diabetes=no] then alive. Coverage:45, accuracy: 0.9574468085106383\n",
      "If [asthma=yes, hypertension=no, obesity=yes, copd=no, sex=male, diabetes=no, renal_chronic=no, imm_supr=no, cardiovascular=no, tobacco=no] then alive. Coverage:286, accuracy: 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "# This may take some time to run (took 12 min on my computer - what about your implementation?)\n",
    "rules = learn_rules_rf (column_list, data, None, 30, 0.9)\n",
    "for rule in rules[:20]:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2022 Marina Barsky. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
